{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: En este Notebook se trabajaran las funciones y las optimizaciones y los mejores resultados de cada una de las funciones es decir las versiones optimizadas ser√°n las que se colocar√°n el los script de python. Dentro de este Notebook utilice time para determinar el tiempo de ejecuci√≥n y poder optimizar y adicionamente utilic√© memory-profile para el uso de la memoria y coloqu√© los resultados. Sim enbargio en los script de python tabn solo coloque la funci√≥n para determinar lo que se solicitaba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMER PUNTO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de tiempo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librer√≠as necesarias para resolver el problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos realizar el la lectura de la ruta y luego leer el archivo y pasarlo a un Dataframe de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'farmers-protest-tweets-2021-2-4.json'\n",
    "dataframe = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos la columna 'date' a formato de fecha y eliminamos la hora para que solo se tenga en cuenta el d√≠a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego extraemos el 'username' de la columna user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['username'] = dataframe['user'].apply(lambda x: x['username'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos las columnas relevantes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = ['date', 'username']\n",
    "dataframe = dataframe[filtered_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora agrupamos por fecha y usuario y contamos la cantidad de tweets y encontramos las top 10 fechas con m√°s tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "top_10_dates = grouped_data.groupby('date')['tweet_count'].sum().nlargest(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos ahora crear para almacenar los resultados en el formato en que se solicita la respuesta\n",
    "Filtramos para date_data es decir para las fechas espec√≠ficas y con este filtro encontramos el usuario con mas publiaciones para la fecha. Por √∫ltimo agreagamos estos resultados a la tupla con el formato requerido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_result = []\n",
    "\n",
    "for date, tweet_count in top_10_dates.items():\n",
    "    date_data = grouped_data[grouped_data['date'] == date]\n",
    "    \n",
    "    top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "    \n",
    "    formatted_result.append((datetime.datetime.strptime(date, '%Y-%m-%d').date(), top_user['username']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos la informaci√≥n resultante y verificamos que el resultado se encuentra en el formato solicitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "print(formatted_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de la funci√≥n TIME:\n",
    "### def q1_time(file_path: str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos todos los pasos ahora unificamos todo dentro de una funci√≥n, agregamos start_time para que mida el tiempo de ejecuci√≥n y lo imprima al ejecutar el codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    dataframe['username'] = dataframe['user'].apply(lambda x: x['username'])\n",
    "\n",
    "    filtered_columns = ['date', 'username']\n",
    "    dataframe = dataframe[filtered_columns]\n",
    "\n",
    "    grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    top_10_dates = grouped_data.groupby('date')['tweet_count'].sum().nlargest(10)\n",
    "\n",
    "\n",
    "    formatted_result = []\n",
    "\n",
    "    for date, tweet_count in top_10_dates.items():\n",
    "        date_data = grouped_data[grouped_data['date'] == date]\n",
    "        top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "        formatted_result.append((datetime.datetime.strptime(date, '%Y-%m-%d').date(), top_user['username']))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n",
    "\n",
    "    return formatted_result\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prueba del codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 19.12430191040039 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo un poco m√°s en lugar de usar una funci√≥n lambda en apply para extraer el 'username', se utilizar√° directamente la indexaci√≥n de diccionario.\n",
    "Del mismo modo se filtrar√°n las columnas relevantes antes de realizar cualquier procesamiento adicional para minizar las iteraciones y por √∫ltimo en lugar de iterar sobre las top 10 fechas y filtrar los datos en cada iteraci√≥n, se procesar√° los datos una vez y luego se iterar√° sobre ellos para encontrar los usuarios con m√°s publicaciones para cada fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time_optimizacion_1(file_path: str):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date']).dt.date\n",
    "    \n",
    "    dataframe['username'] = [user.get('username', None) for user in dataframe['user']]\n",
    "    \n",
    "    dataframe = dataframe[['date', 'username']]\n",
    "    \n",
    "    grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    \n",
    "    top_10_dates = grouped_data.groupby('date')['tweet_count'].sum().nlargest(10)\n",
    "    \n",
    "    formatted_result = []\n",
    "    \n",
    "    for date in top_10_dates.index:\n",
    "        date_data = grouped_data[grouped_data['date'] == date]\n",
    "        top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "        formatted_result.append((date, top_user['username']))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n",
    "    \n",
    "    return formatted_result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prueba para verificar si el tiempo de ejecuci√≥n disminuy√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 13.605211019515991 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time_optimizacion_1(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de la funci√≥n MEMORY:\n",
    "### def q1_memory(file_path: str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la prueba de memoria se utiliza el Script de Python ya que la librer√≠a memory-profile no se ejecuta adecuadamente con un Notebook "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funci√≥n primaria es: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory(file_path: str):\n",
    "    \n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    dataframe['username'] = dataframe['user'].apply(lambda x: x['username'])\n",
    "\n",
    "    filtered_columns = ['date', 'username']\n",
    "    dataframe = dataframe[filtered_columns]\n",
    "\n",
    "    grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    top_10_dates = grouped_data.groupby('date')['tweet_count'].sum().nlargest(10)\n",
    "\n",
    "\n",
    "    formatted_result = []\n",
    "\n",
    "    for date, tweet_count in top_10_dates.items():\n",
    "        date_data = grouped_data[grouped_data['date'] == date]\n",
    "        top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "        formatted_result.append((datetime.datetime.strptime(date, '%Y-%m-%d').date(), top_user['username']))\n",
    "\n",
    "    return formatted_result\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos este resultado cuando aplicamos el script en Python como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "import pandas as pd\n",
    "\n",
    "@profile\n",
    "def q1_memory(file_path: str):\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')\n",
    "    dataframe['username'] = dataframe['user'].apply(lambda x: x['username'])\n",
    "\n",
    "    filtered_columns = ['date', 'username']\n",
    "    dataframe = dataframe[filtered_columns]\n",
    "\n",
    "    grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    \n",
    "    del dataframe\n",
    "    \n",
    "    unique_dates = grouped_data['date'].unique()\n",
    "    top_10_dates = grouped_data[grouped_data['date'].isin(unique_dates[:10])]\n",
    "\n",
    "    formatted_result = []\n",
    "\n",
    "    for date in top_10_dates['date'].unique():\n",
    "        date_data = top_10_dates[top_10_dates['date'] == date]\n",
    "        top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "        formatted_result.append((date, top_user['username']))\n",
    "\n",
    "\n",
    "    return formatted_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/Users/edwardguzman/Desktop/challenge_DE/farmers-protest-tweets-2021-2-4.json'\n",
    "    q1_memory(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de memoria es"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     6     96.0 MiB     96.0 MiB           1       @profile\n",
    "     7                                             def q1_time(file_path: str):\n",
    "     8                                             \n",
    "     9   1614.6 MiB   1518.5 MiB           1       dataframe = pd.read_json(file_path, lines=True)\n",
    "    10                                         \n",
    "    11   1615.7 MiB      1.2 MiB           1       dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    12   1615.8 MiB      0.1 MiB           1       dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')\n",
    "    13                                         \n",
    "    14   1615.8 MiB    -18.6 MiB      234815       dataframe['username'] = dataframe['user'].apply(lambda x: x['username'])\n",
    "    15                                         \n",
    "    16   1597.2 MiB    -18.7 MiB           1       filtered_columns = ['date', 'username']\n",
    "    17   1490.5 MiB   -106.7 MiB           1       dataframe = dataframe[filtered_columns]\n",
    "    18                                         \n",
    "    19   1449.8 MiB    -40.7 MiB           1       grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    20   1446.0 MiB     -3.9 MiB           1       top_10_dates = grouped_data.groupby('date')['tweet_count'].sum().nlargest(10)\n",
    "    21                                         \n",
    "    22                                         \n",
    "    23   1446.0 MiB      0.0 MiB           1       formatted_result = []\n",
    "    24                                         \n",
    "    25   1446.2 MiB    -19.7 MiB          11       for date, tweet_count in top_10_dates.items():\n",
    "    26   1446.1 MiB    -19.6 MiB          10       date_data = grouped_data[grouped_data['date'] == date]\n",
    "    27   1446.2 MiB    -18.8 MiB          10       top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "    28   1446.2 MiB    -19.7 MiB          10       formatted_result.append((datetime.datetime.strptime(date, '%Y-%m-%d').date(), top_user['username']))\n",
    "    29                                         \n",
    "    30                                         \n",
    "    31                                         \n",
    "    32   1443.5 MiB     -2.7 MiB           1       return formatted_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos realizamos la optimizaci√≥n del codigo, en este caso eliminamos el dataframe luego de ser filtrado por √∫ltimo en lugar de calcular top_10_dates usando nlargest(10) en todo el DataFrame grouped_data, aplicaremos la operaci√≥n solo a las fechas √∫nicas en grouped_data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory_optimized(file_path: str):\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date']).dt.date\n",
    "    dataframe['username'] = dataframe['user'].apply(lambda x: x.get('username', None))\n",
    "\n",
    "    grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    del dataframe\n",
    "    top_10_dates = grouped_data.groupby('date')['tweet_count'].sum().nlargest(10).index\n",
    "\n",
    "    formatted_result = []\n",
    "\n",
    "    for date in top_10_dates:\n",
    "        date_data = grouped_data[grouped_data['date'] == date]\n",
    "        top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "        formatted_result.append((date, top_user['username']))\n",
    "\n",
    "    return formatted_result\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     4     96.0 MiB     96.0 MiB           1   @profile\n",
    "     5                                         def q1_time(file_path: str):\n",
    "     6   1565.4 MiB   1469.4 MiB           1   dataframe = pd.read_json(file_path, lines=True)\n",
    "     7                                         \n",
    "     8   1566.6 MiB      1.2 MiB           1   dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "     9   1566.7 MiB      0.1 MiB           1   dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')\n",
    "    10   1566.7 MiB    -18.7 MiB      234815   dataframe['username'] = dataframe['user'].apply(lambda x: x['username'])\n",
    "    11                                         \n",
    "    12   1548.0 MiB    -18.7 MiB           1   filtered_columns = ['date', 'username']\n",
    "    13   1474.8 MiB    -73.2 MiB           1   dataframe = dataframe[filtered_columns]\n",
    "    14                                         \n",
    "    15   1434.0 MiB    -40.8 MiB           1   grouped_data = dataframe.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "    16                                             \n",
    "    17   1432.0 MiB     -2.0 MiB           1   del dataframe\n",
    "    18                                             \n",
    "    19   1430.0 MiB     -2.0 MiB           1   unique_dates = grouped_data['date'].unique()\n",
    "    20   1428.4 MiB     -1.6 MiB           1   top_10_dates = grouped_data[grouped_data['date'].isin(unique_dates[:10])]\n",
    "    21                                         \n",
    "    22   1428.4 MiB      0.0 MiB           1   formatted_result = []\n",
    "    23                                         \n",
    "    24   1428.6 MiB     -4.8 MiB          11   for date in top_10_dates['date'].unique():\n",
    "    25   1428.5 MiB     -4.7 MiB          10   date_data = top_10_dates[top_10_dates['date'] == date]\n",
    "    26   1428.6 MiB     -3.5 MiB          10   top_user = date_data.loc[date_data['tweet_count'].idxmax()]\n",
    "    27   1428.6 MiB     -4.8 MiB          10   formatted_result.append((date, top_user['username']))\n",
    "    28                                         \n",
    "    29                                         \n",
    "    30   1428.0 MiB     -0.6 MiB           1   return formatted_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGUNDO PUNTO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import regex as re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos la base y la convertimos a un dataframe de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'farmers-protest-tweets-2021-2-4.json'\n",
    "dataframe = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos como primera medida el contenido de los tweets y creamos un diccionario para contar lo emojis cada vez que aparezcan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataframe['content']\n",
    "emoji_counts = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteramos ahora sobre cada tweet para encontrar todos los que son emojis utilizando expresiones regulares. Del mismo modo filtramos los emojis oara contar su frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in text:\n",
    "    emojis = re.findall(r'\\X', tweet)\n",
    "    for emoji_char in emojis:\n",
    "        if emoji_char in emoji.UNICODE_EMOJI['en']:\n",
    "            if emoji_char in emoji_counts:\n",
    "                emoji_counts[emoji_char] += 1\n",
    "            else:\n",
    "                emoji_counts[emoji_char] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos un dataframe con el diccionario de emojis resultado de la iteraci√≥n. Lo organizamos por conteo de los emojis y tomamos los primeros 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_df = pd.DataFrame(list(emoji_counts.items()), columns=['Emoji', 'Count'])\n",
    "emoji_df = emoji_df.sort_values(by='Count', ascending=False)\n",
    "top_10_emojis = emoji_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 emojis m√°s utilizados:\n",
      "   Emoji  Count\n",
      "48     üôè   5049\n",
      "29     üòÇ   3072\n",
      "0      üöú   2972\n",
      "1      üåæ   2182\n",
      "6     üáÆüá≥   2086\n",
      "15     ü§£   1668\n",
      "36     ‚úä   1642\n",
      "56    ‚ù§Ô∏è   1382\n",
      "11    üôèüèª   1317\n",
      "32     üíö   1040\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 emojis m√°s utilizados:\")\n",
    "print(top_10_emojis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa las manos juntas estan como un emoji diferente pero lo podemos unir por color tomado todos los colores. Este ejercicio se realiza tan solo para este emoji realizando una agrupaci√≥n de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_praying_hands_emojis = ['üôè', 'üôèüèª', 'üôèüèº', 'üôèüèΩ', 'üôèüèæ', 'üôèüèø']\n",
    "\n",
    "for tweet in text:\n",
    "    emojis = re.findall(r'\\X', tweet)\n",
    "    for emoji_char in emojis:\n",
    "        if emoji_char in grouped_praying_hands_emojis:\n",
    "            emoji_base = 'üôè'  \n",
    "            if emoji_base in emoji_counts:\n",
    "                emoji_counts[emoji_base] += 1\n",
    "            else:\n",
    "                emoji_counts[emoji_base] = 1\n",
    "        elif emoji_char in emoji.UNICODE_EMOJI['en']:\n",
    "            if emoji_char in emoji_counts:\n",
    "                emoji_counts[emoji_char] += 1\n",
    "            else:\n",
    "                emoji_counts[emoji_char] = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la impresion de los resultados para verificar que no se cuenten como independientes sino como el mismo emoji las manos juntas, sin embargo esto puede suceder para todos los emojis que pueden tener cambio de color como la mayor√≠a de manos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 emojis m√°s utilizados:\n",
      "   Emoji  Count\n",
      "48     üôè  12335\n",
      "29     üòÇ   6144\n",
      "0      üöú   5944\n",
      "1      üåæ   4364\n",
      "6     üáÆüá≥   4172\n",
      "15     ü§£   3336\n",
      "36     ‚úä   3284\n",
      "56    ‚ù§Ô∏è   2764\n",
      "32     üíö   2080\n",
      "7      üëá   1746\n"
     ]
    }
   ],
   "source": [
    "emoji_df = pd.DataFrame(list(emoji_counts.items()), columns=['Emoji', 'Count'])\n",
    "emoji_df = emoji_df.sort_values(by='Count', ascending=False)\n",
    "top_10_emojis = emoji_df.head(10)\n",
    "print(\"Top 10 emojis m√°s utilizados:\")\n",
    "print(top_10_emojis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de la funci√≥n TIME:\n",
    "### def q2_time(file_path: str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unificamos todo el codigo anterior y creamos la funci√≥n aplicando la librer√≠a time para medir el tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "def q2_time(file_path: str):\n",
    "    start_time = time.time()\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    text = dataframe['content']\n",
    "    emoji_counts = {}\n",
    "    grouped_praying_hands_emojis = ['üôè', 'üôèüèª', 'üôèüèº', 'üôèüèΩ', 'üôèüèæ', 'üôèüèø']\n",
    "\n",
    "    for tweet in text:\n",
    "        emojis = re.findall(r'\\X', tweet)\n",
    "        for emoji_char in emojis:\n",
    "            if emoji_char in grouped_praying_hands_emojis:\n",
    "                emoji_base = 'üôè'  \n",
    "                if emoji_base in emoji_counts:\n",
    "                    emoji_counts[emoji_base] += 1\n",
    "                else:\n",
    "                    emoji_counts[emoji_base] = 1\n",
    "            elif emoji_char in emoji.UNICODE_EMOJI['en']:\n",
    "                if emoji_char in emoji_counts:\n",
    "                    emoji_counts[emoji_char] += 1\n",
    "                else:\n",
    "                    emoji_counts[emoji_char] = 1\n",
    "\n",
    "    emoji_df = pd.DataFrame(list(emoji_counts.items()), columns=['Emoji', 'Count'])\n",
    "    emoji_df = emoji_df.sort_values(by='Count', ascending=False)\n",
    "    top_10_emojis = emoji_df.head(10)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n",
    "    \n",
    "    formatted_result = [(row['Emoji'], row['Count']) for _, row in top_10_emojis.iterrows()]\n",
    "    \n",
    "    return formatted_result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la ejecuci√≥n de la funci√≥n para verificar el Top 10 as√≠ como el tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 76.3860969543457 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 7286),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1642),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üíö', 1040),\n",
       " ('üëá', 873)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la optimizaci√≥n para tener un menor tiempo de ejecuci√≥n, para esto se uso un conjunto (set) para grouped_praying_hands_emojis en lugar de una lista ya que,  permite una b√∫squeda m√°s eficiente de los emojis de manos juntas. Luego se simplific√≥ la l√≥gica de conteo de emojis utilizando el m√©todo .get() de los diccionarios de Python para obtener el recuento del emoji. Del mismo modo, se elimin√≥ el uso de la variable text y se trabaj√≥ directamente con la columna 'content' del DataFrame. Po √∫ltimo, se utiliz√≥ el m√©todo nlargest() de Pandas para obtener los 10 emojis con el recuento m√°s alto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "def q2_time_optimized(file_path: str):\n",
    "    start_time = time.time()\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    emoji_counts = {}\n",
    "    grouped_praying_hands_emojis = {'üôè', 'üôèüèª', 'üôèüèº', 'üôèüèΩ', 'üôèüèæ', 'üôèüèø'}\n",
    "\n",
    "    for tweet in dataframe['content']:\n",
    "        emojis = re.findall(r'\\X', tweet)\n",
    "        for emoji_char in emojis:\n",
    "            if emoji_char in grouped_praying_hands_emojis:\n",
    "                emoji_base = 'üôè'  \n",
    "            elif emoji_char in emoji.UNICODE_EMOJI['en']:\n",
    "                emoji_base = emoji_char\n",
    "            else:\n",
    "                continue \n",
    "            emoji_counts[emoji_base] = emoji_counts.get(emoji_base, 0) + 1\n",
    "\n",
    "    emoji_df = pd.DataFrame(emoji_counts.items(), columns=['Emoji', 'Count'])\n",
    "    top_10_emojis = emoji_df.nlargest(10, 'Count')\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n",
    "    \n",
    "    formatted_result = [(row['Emoji'], row['Count']) for _, row in top_10_emojis.iterrows()]\n",
    "    \n",
    "    return formatted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 72.37688517570496 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 7286),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1642),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üíö', 1040),\n",
       " ('üëá', 873)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time_optimized(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de la funci√≥n MEMORY:\n",
    "### def q2_memory(file_path: str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se parte del codigo base para verificar cual es el uso de memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import regex as re\n",
    "\n",
    "def q2_memory(file_path: str):\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    text = dataframe['content']\n",
    "    emoji_counts = {}\n",
    "    grouped_praying_hands_emojis = ['üôè', 'üôèüèª', 'üôèüèº', 'üôèüèΩ', 'üôèüèæ', 'üôèüèø']\n",
    "\n",
    "    for tweet in text:\n",
    "        emojis = re.findall(r'\\X', tweet)\n",
    "        for emoji_char in emojis:\n",
    "            if emoji_char in grouped_praying_hands_emojis:\n",
    "                emoji_base = 'üôè'  \n",
    "                if emoji_base in emoji_counts:\n",
    "                    emoji_counts[emoji_base] += 1\n",
    "                else:\n",
    "                    emoji_counts[emoji_base] = 1\n",
    "            elif emoji_char in emoji.UNICODE_EMOJI['en']:\n",
    "                if emoji_char in emoji_counts:\n",
    "                    emoji_counts[emoji_char] += 1\n",
    "                else:\n",
    "                    emoji_counts[emoji_char] = 1\n",
    "\n",
    "    emoji_df = pd.DataFrame(list(emoji_counts.items()), columns=['Emoji', 'Count'])\n",
    "    emoji_df = emoji_df.sort_values(by='Count', ascending=False)\n",
    "    top_10_emojis = emoji_df.head(10)\n",
    "    \n",
    "    formatted_result = [(row['Emoji'], row['Count']) for _, row in top_10_emojis.iterrows()]\n",
    "    \n",
    "    return formatted_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôè', 7286),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1642),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üíö', 1040),\n",
       " ('üëá', 873)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el uso de memoria para este codigo lo primero que se realiza es utilizar operaciones vectorizadas de Pandas para que en vez de iterar sobre cada fila de dataframe['content'] para contar los emojis, se podr√≠a utilizar la operaci√≥n sobre toda la columna. Lo segundo es eliminar las variables innecesarias despu√©s de calcular los recuentos de emoji y crear el DataFrame se eliminan kas variables temporales. del mismo modo se usan estructuras de datos m√°s eficientes para almacenar y procesar los recuentos de emoji en lugar de un diccionario de Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import regex as re\n",
    "\n",
    "def q2_memory_optimized(file_path: str):\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    text = dataframe['content']\n",
    "    emoji_counts = {}\n",
    "\n",
    "    for tweet in text:\n",
    "        emojis = re.findall(r'\\X', tweet)\n",
    "        for emoji_char in emojis:\n",
    "            if emoji_char in emoji.UNICODE_EMOJI['en']:\n",
    "                if emoji_char in emoji_counts:\n",
    "                    emoji_counts[emoji_char] += 1\n",
    "                else:\n",
    "                    emoji_counts[emoji_char] = 1\n",
    "\n",
    "    emoji_df = pd.DataFrame(list(emoji_counts.items()), columns=['Emoji', 'Count'])\n",
    "    top_10_emojis = emoji_df.sort_values(by='Count', ascending=False).head(10)\n",
    "\n",
    "    formatted_result = [(row['Emoji'], row['Count']) for _, row in top_10_emojis.iterrows()]\n",
    "    \n",
    "    return formatted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôè', 5049),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1642),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory_optimized(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERCER PUNTO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo tomamos el contenido del tweet e inicializamos un diccionario para contar las menciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataframe['content']\n",
    "mention_counts = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora iteramos sobre cada item del tweet y encontramos todas las menciones (@) en el tweet utilizando expresiones regulares as√≠ mismo las filtramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    mentions = re.findall(r'@(\\w+)', tweet)\n",
    "    for mention in mentions:\n",
    "        if mention in mention_counts:\n",
    "            mention_counts[mention] += 1\n",
    "        else:\n",
    "            mention_counts[mention] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos el diccionario de las menciones aun dataframe y lo organizamos tomando los 10 de mayor conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_df = pd.DataFrame(list(mention_counts.items()), columns=['Usuario', 'Conteo'])\n",
    "top_10_mencionados = mention_df.sort_values(by='Conteo', ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos lo resultados para verificar que este funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 usuarios m√°s mencionados:\n",
      "             Usuario  Conteo\n",
      "0       narendramodi    2261\n",
      "2    Kisanektamorcha    1836\n",
      "56   RakeshTikaitBKU    1639\n",
      "9           PMOIndia    1422\n",
      "84       RahulGandhi    1125\n",
      "188    GretaThunberg    1046\n",
      "321      RaviSinghKA    1015\n",
      "444          rihanna     972\n",
      "147    UNHumanRights     962\n",
      "187      meenaharris     925\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 usuarios m√°s mencionados:\")\n",
    "print(top_10_mencionados)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de la funci√≥n TIME:\n",
    "### def q3_time(file_path: str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def q3_time(file_path: str):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    tweets = dataframe['content']\n",
    "    mention_counts = {}\n",
    "\n",
    "    for tweet in tweets:\n",
    "        mentions = re.findall(r'@(\\w+)', tweet)\n",
    "        for mention in mentions:\n",
    "            if mention in mention_counts:\n",
    "                mention_counts[mention] += 1\n",
    "            else:\n",
    "                mention_counts[mention] = 1\n",
    "\n",
    "\n",
    "    mention_df = pd.DataFrame(list(mention_counts.items()), columns=['User', 'Count'])\n",
    "    top_10_mencionados = mention_df.sort_values(by='Count', ascending=False).head(10)\n",
    "    formatted_result = [(row['User'], row['Count']) for _, row in top_10_mencionados.iterrows()]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n",
    "\n",
    "    return formatted_result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 44.93638777732849 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar la funci√≥n utilizaremos collections.Counter en lugar de mantener un diccionario mention_counts y realizar comprobaciones de pertenencia en cada iteraci√≥n. Tambien se puede evitar la creaci√≥n innecesaria de un DataFrame completo y por √∫ltimo podemos usar Counter.most_common(10) para obtener directamente las 10 menciones m√°s comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "def q3_time_optimized(file_path: str):\n",
    "    start_time = time.time()\n",
    "\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    tweets = dataframe['content']\n",
    "    \n",
    "    mention_counts = Counter()\n",
    "    for tweet in tweets:\n",
    "        mentions = re.findall(r'@(\\w+)', tweet)\n",
    "        mention_counts.update(mentions)\n",
    "    \n",
    "    top_10_mencionados = mention_counts.most_common(10)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n",
    "\n",
    "    return top_10_mencionados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 37.032829999923706 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time_optimized(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de la funci√≥n Memory:\n",
    "### def q3_memory(file_path: str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos de nuevo de la funci√≥n original para poder optimizarla con respecto al uso de la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def q3_memory(file_path: str):\n",
    "    \n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    tweets = dataframe['content']\n",
    "    mention_counts = {}\n",
    "\n",
    "    for tweet in tweets:\n",
    "        mentions = re.findall(r'@(\\w+)', tweet)\n",
    "        for mention in mentions:\n",
    "            if mention in mention_counts:\n",
    "                mention_counts[mention] += 1\n",
    "            else:\n",
    "                mention_counts[mention] = 1\n",
    "\n",
    "\n",
    "    mention_df = pd.DataFrame(list(mention_counts.items()), columns=['User', 'Count'])\n",
    "    top_10_mencionados = mention_df.sort_values(by='Count', ascending=False).head(10)\n",
    "    formatted_result = [(row['User'], row['Count']) for _, row in top_10_mencionados.iterrows()]\n",
    "      \n",
    "\n",
    "    return formatted_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/Users/edwardguzman/Desktop/challenge_DE/farmers-protest-tweets-2021-2-4.json'\n",
    "    result = q3_memory(file_path)\n",
    "    print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     5     98.4 MiB     98.4 MiB           1   @profile\n",
    "     6                                         def q3_memory(file_path: str):\n",
    "     7                                           \n",
    "     8                                         \n",
    "     9   1550.7 MiB   1452.3 MiB           1   dataframe = pd.read_json(file_path, lines=True)\n",
    "    10   1550.7 MiB      0.0 MiB           1   tweets = dataframe['content']\n",
    "    11   1550.7 MiB      0.0 MiB           1   mention_counts = {}\n",
    "    12                                         \n",
    "    13   1551.0 MiB -86270.1 MiB      117408   for tweet in tweets:\n",
    "    14   1551.0 MiB -86268.7 MiB      117407   mentions = re.findall(r'@(\\w+)', tweet)\n",
    "    15   1551.0 MiB -162634.9 MiB      221473  for mention in mentions:\n",
    "    16   1551.0 MiB -76364.8 MiB      104066   if mention in mention_counts:\n",
    "    17   1551.0 MiB -66847.7 MiB       88391   mention_counts[mention] += 1\n",
    "    18                                         else:\n",
    "    19   1551.0 MiB  -9518.1 MiB       15675   mention_counts[mention] = 1\n",
    "    20                                         \n",
    "    21                                         \n",
    "    22   1530.1 MiB    -20.9 MiB           1   mention_df = pd.DataFrame(list(mention_counts.items()), columns=['User', 'Count'])\n",
    "    23   1530.5 MiB      0.5 MiB           1   top_10_mencionados = mention_df.sort_values(by='Count', ascending=False).head(10)\n",
    "    24   1530.5 MiB      0.0 MiB          13   formatted_result = [(row['User'], row['Count']) for _, row in top_10_mencionados.iterrows()]\n",
    "    25                                             \n",
    "    26   1530.5 MiB      0.0 MiB           1   return formatted_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos la optimizaci√≥n para revisar si tenemos un mejor rendimiento de memoria. Evitamos la creaci√≥n de un diccionario mention_counts para almacenar todas las menciones y sus recuentos y mas bien utilizamos collections.Counter para contar las menciones directamente mientras iteramos a trav√©s de los tweets. Adem√°s, podemos usar Counter.most_common(10) para obtener directamente las 10 menciones m√°s comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def q3_memory_optimized(file_path: str):\n",
    "\n",
    "    dataframe = pd.read_json(file_path, lines=True)\n",
    "    tweets = dataframe['content']\n",
    "    \n",
    "    mention_counts = Counter()\n",
    "    for tweet in tweets:\n",
    "        mentions = re.findall(r'@(\\w+)', tweet)\n",
    "        mention_counts.update(mentions)\n",
    "    \n",
    "    top_10_mencionados = mention_counts.most_common(10)\n",
    "    \n",
    "    return top_10_mencionados\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     7     98.3 MiB     98.3 MiB           1   @profile\n",
    "     8                                         def q3_memory_optimized(file_path: str):\n",
    "     9                                             \n",
    "    10                                         \n",
    "    11   1512.5 MiB   1464.1 MiB           1       dataframe = pd.read_json(file_path, lines=True)\n",
    "    12   1512.5 MiB      0.0 MiB           1       tweets = dataframe['content']\n",
    "    13   1512.5 MiB      0.0 MiB           1       mention_counts = Counter()\n",
    "    14                                         \n",
    "    15   1512.7 MiB -86270.1 MiB      117408       for tweet in tweets:\n",
    "    16   1512.7 MiB -86268.7 MiB      117407           mentions = re.findall(r'@(\\w+)', tweet)\n",
    "    17   1512.7 MiB -86269.9 MiB      117407           mention_counts.update(mentions)\n",
    "    18                                             \n",
    "    19   1501.5 MiB     -1.2 MiB           1       top_10_mencionados = mention_counts.most_common(10)\n",
    "    20                                             \n",
    "    21                                             \n",
    "    22   1501.5 MiB      0.0 MiB           1       return top_10_mencionados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
